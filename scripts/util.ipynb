{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e6e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following resources on https://thestudyvarta.blogspot.com/:\n",
      "https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js\n",
      "https://blogger.googleusercontent.com/img/a/AVvXsEgaty7CB8OkQW5FIjoNvEtePC4zwLc23C7d0koGKqRZjcjT_98aNsqr3WoUPpzGZUhBAMDla1c5YJjD9jSuoKpBw0069qQ9gd_xyM_2dxHJGErvi21m3BZmDUud9vqr1DDDdE8lO1A_p9XdShk21a2euIN5ltrMBALkiXDOGxejZW5XQRmPdHawZSEH=s793\n",
      "https://blogger.googleusercontent.com/img/a/AVvXsEjpKtnXSRz-oxBIbeGTtfdi5Dpn_qXShEXRIVm1tN5E976Us57s7rJ5OO53zdaUdKecZP729qpWgZ0O4EQDJIt_JOmcGsV_ddwtAAVKJq9wRtWb5F1Tbe4evSLTT5rS3LLF018BzLKb7UMt1_t80HEXcOQtt7FG-Doo93hARplLW2lZ-AJeGLTX9c5k=s793\n",
      "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhwJSBqchgQikg5ytZNHl1PTUfEDWxiZYok4bQMwDKXWb_t71JSQgpB7WINK0wviKBM6o4IKrnhYiSoSwi-AViFAGp_Fp4VdMP4qjholRFold0G6w6Yi-aZfhoEeatrm89jun5QPhJHV5oqehfnkQTMDXBf_Gehb04k0OUurMJPVlBeDWTWRRVtdl3jJzM/w640/carlos-muza-hpjSkU2UYSU-unsplash.jpg\n",
      "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi1-fp1HQbM36ALo-HY7u7q9mPJnN5qcMLx2aytqhgRCXQbqTN8Lvu3AU3zs_n_x88j-2ReM29RBWyselTiIe8n9Ghx2XBEcg-_pn3oNTbcSAoGUBZTpN0qnVlqYaxqJC0kXZfX2ZCnGKokgNRxkUyONyl9Bc85Sxfj6HqxDrm1dtuvifs3QIYHoWxCUkY/w640/digital-4368784_1280.jpg\n",
      "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiicsNBHhWMfNjYVjHr4qttKvGx-R3raQca7AYBjTFu6ft1GQ2NMQrJYX5lNw_3T5X70wE8KiAQTxqqDpj6CO4nXG6T_d2JVBTtEGGj3D_sqtqLQN9PGl2E2XrLCoBhlcIhRIhM6v4ZTQ9Skhqz855aXyBr23SqQV7a3EnPvikJYrTkx7D-ckm6WTBT/w640/backlinks-7791414_1280.webp\n",
      "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-Nh9GBJEXgt8i2-CMl4LQX_Y1zsnVUoPYNZEdyB7sngPQrQ-Ra9qHevzXwv2VNUhO6XtUMT6S-PhsR7ULeiWBJHDVYhJtJ9tPGqeJvN-QoE385rqipMKWzr5fVvbLJ9DhB02ZfYMH1rofPHvB9z0QfNbRPVFkR2EqsWzhbwYxVBLGL4FPXtqlfC-C1bk/w640/data.jpg\n",
      "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUhaa9iAOV34pxHHwaCbOYQ7bPqsAK33Qg5PsiCTq9yBPB7BmNoj4JhFo8gAAk3zmgiB2evEI5ZDCmmmPZkX9X0XrgTXe2YMoJlKsFH0nXLO8b2W4c5kEKLBIq1nPlMMO2ULfqLX54SVf8mI_pljy131hWRRsVDkFHPThrFENt_O__XUZnuZBFm7XAzd0/w640/18140.jpg\n",
      "https://cdn.onesignal.com/sdks/OneSignalSDK.js\n",
      "https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700,700i\n",
      "https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css\n",
      "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6062872757250188&host=ca-host-pub-1556223355139109\n",
      "https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\n",
      "https://thestudyvarta.blogspot.com/\n",
      "https://thestudyvarta.blogspot.com/.https:/www.facebook.com/Deeprajsrivastav9119\n",
      "https://thestudyvarta.blogspot.com//study-varta/study-varta/\n",
      "https://thestudyvarta.blogspot.com/2023/05/what-are-backlinks.html\n",
      "https://thestudyvarta.blogspot.com/2023/07/career-in-data-analytics.html\n",
      "https://thestudyvarta.blogspot.com/2023/07/career-plan-in-data-science.html\n",
      "https://thestudyvarta.blogspot.com/2023/07/the-difference-between-business.html\n",
      "https://thestudyvarta.blogspot.com/2023/07/why-data-science-and-data-analyst-are.html\n",
      "https://thestudyvarta.blogspot.com/p/contact-us.html\n",
      "https://thestudyvarta.blogspot.com/p/disclaimer.html\n",
      "https://thestudyvarta.blogspot.com/p/privacy-policy.html\n",
      "https://thestudyvarta.blogspot.com/search\n",
      "https://thestudyvarta.blogspot.com/search/label/Amazon%20Online%20Internet\n",
      "https://thestudyvarta.blogspot.com/search/label/Amazon%20Web\n",
      "https://thestudyvarta.blogspot.com/search/label/Coders%20of%20Coading\n",
      "https://thestudyvarta.blogspot.com/search/label/Data%20Analyst\n",
      "https://thestudyvarta.blogspot.com/search/label/Data%20Science\n",
      "https://thestudyvarta.blogspot.com/search/label/EXAM\n",
      "https://thestudyvarta.blogspot.com/search/label/Exam%20News%202021\n",
      "https://thestudyvarta.blogspot.com/search/label/GOVERNMENT%20EXAM\n",
      "https://thestudyvarta.blogspot.com/search/label/Instagram\n",
      "https://thestudyvarta.blogspot.com/search/label/Python%20Language\n",
      "https://thestudyvarta.blogspot.com/search/label/Python%20for%20Data%20Science\n",
      "https://thestudyvarta.blogspot.com/search/label/SARKARI%20RESULT\n",
      "https://thestudyvarta.blogspot.com/search/label/Social%20Site\n",
      "https://thestudyvarta.blogspot.com/search?updated-max=2023-05-27T02:46:00-07:00&max-results=7\n",
      "https://twitter.com/DeeprajSri\n",
      "https://www.blogger.com/static/v1/widgets/2218197725-widgets.js\n",
      "https://www.facebook.com/Deeprajsrivastav9119\n",
      "https://www.googletagmanager.com/gtag/js?id=G-M6MGF6KXWB\n",
      "https://www.instagram.com/deepraj._sri9119/\n",
      "https://www.linkedin.com/in/deeprajsrivastav\n",
      "https://www.linkedin.com/in/deeprajsrivastav/\n",
      "https://www.thestudyvarta.online/\n",
      "https://www.thestudyvarta.online/p/about-us.html\n",
      "https://www.thestudyvarta.online/p/terms.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import os\n",
    "\n",
    "def is_valid(url):\n",
    "    \"\"\"Checks if the given URL is a valid HTTP or HTTPS URL.\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and parsed.scheme in (\"http\", \"https\")\n",
    "\n",
    "def get_all_resources(url, download_path=\"downloaded_resources\"):\n",
    "    \"\"\"\n",
    "    Fetches the HTML of a URL and extracts links to various resources.\n",
    "    Optionally downloads some of these resources.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        base_url = urljoin(url, '/')\n",
    "        resources = set()\n",
    "\n",
    "        # Find links in <a> tags\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            absolute_url = urljoin(base_url, link['href'])\n",
    "            if is_valid(absolute_url):\n",
    "                resources.add(absolute_url)\n",
    "\n",
    "        # Find links to images\n",
    "        for img in soup.find_all('img', src=True):\n",
    "            absolute_url = urljoin(base_url, img['src'])\n",
    "            if is_valid(absolute_url):\n",
    "                resources.add(absolute_url)\n",
    "\n",
    "        # Find links to scripts\n",
    "        for script in soup.find_all('script', src=True):\n",
    "            absolute_url = urljoin(base_url, script['src'])\n",
    "            if is_valid(absolute_url):\n",
    "                resources.add(absolute_url)\n",
    "\n",
    "        # Find links to stylesheets\n",
    "        for link in soup.find_all('link', rel='stylesheet', href=True):\n",
    "            absolute_url = urljoin(base_url, link['href'])\n",
    "            if is_valid(absolute_url):\n",
    "                resources.add(absolute_url)\n",
    "\n",
    "        # Find links to other common resources (you can extend this list)\n",
    "        for source in soup.find_all('source', src=True):\n",
    "            absolute_url = urljoin(base_url, source['src'])\n",
    "            if is_valid(absolute_url):\n",
    "                resources.add(absolute_url)\n",
    "        for iframe in soup.find_all('iframe', src=True):\n",
    "            absolute_url = urljoin(base_url, iframe['src'])\n",
    "            if is_valid(absolute_url):\n",
    "                resources.add(absolute_url)\n",
    "        for audio in soup.find_all('audio', src=True):\n",
    "            absolute_url = urljoin(base_url, audio['src'])\n",
    "            if is_valid(absolute_url):\n",
    "                resources.add(absolute_url)\n",
    "        for video in soup.find_all('video', src=True):\n",
    "            for source in video.find_all('source', src=True):\n",
    "                absolute_url = urljoin(base_url, source['src'])\n",
    "                if is_valid(absolute_url):\n",
    "                    resources.add(absolute_url)\n",
    "            if video.has_attr('src') and is_valid(urljoin(base_url, video['src'])):\n",
    "                resources.add(urljoin(base_url, video['src']))\n",
    "\n",
    "        print(f\"Found the following resources on {url}:\")\n",
    "        for resource in sorted(list(resources)):\n",
    "            print(resource)\n",
    "\n",
    "        # Optional: Download the found resources\n",
    "        if download_path:\n",
    "            os.makedirs(download_path, exist_ok=True)\n",
    "            print(f\"\\nAttempting to download some resources to: {download_path}\")\n",
    "            for resource_url in resources:\n",
    "                try:\n",
    "                    resource_response = requests.get(resource_url, stream=True)\n",
    "                    resource_response.raise_for_status()\n",
    "\n",
    "                    parsed_url = urlparse(resource_url)\n",
    "                    filename = os.path.join(download_path, os.path.basename(parsed_url.path))\n",
    "\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        for chunk in resource_response.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "                    print(f\"Downloaded: {os.path.basename(filename)}\")\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"Error downloading {resource_url}: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing {resource_url}: {e}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    target_url = 'https://thestudyvarta.blogspot.com/'\n",
    "    download = input(\"Do you want to download some of the found resources? (yes/no): \").lower()\n",
    "    download_path = \"downloaded_resources\" if download == \"yes\" else None\n",
    "    get_all_resources(target_url, download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba3c38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unused resources on https://thestudyvarta.blogspot.com/:\n",
      "https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700,700i\n",
      "https://thestudyvarta.blogspot.com/.https:/www.facebook.com/Deeprajsrivastav9119\n",
      "https://thestudyvarta.blogspot.com/search?updated-max=2023-05-27T02:46:00-07:00&max-results=7\n",
      "https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "def is_valid(url):\n",
    "    \"\"\"Checks if the given URL is a valid HTTP or HTTPS URL.\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and parsed.scheme in (\"http\", \"https\")\n",
    "\n",
    "def get_unused_resources(url):\n",
    "    \"\"\"Identifies unused resources on a webpage.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        base_url = urljoin(url, '/')\n",
    "        resources = set()\n",
    "\n",
    "        # Extract all resources\n",
    "        for tag, attr in [('a', 'href'), ('img', 'src'), ('script', 'src'), ('link', 'href'), ('source', 'src'), ('iframe', 'src'), ('audio', 'src'), ('video', 'src')]:\n",
    "            for element in soup.find_all(tag, **{attr: True}):\n",
    "                absolute_url = urljoin(base_url, element[attr])\n",
    "                if is_valid(absolute_url):\n",
    "                    resources.add(absolute_url)\n",
    "\n",
    "        # Check if resources are used in the HTML\n",
    "        unused_resources = []\n",
    "        html_content = response.text\n",
    "        for resource in resources:\n",
    "            if resource not in html_content:\n",
    "                unused_resources.append(resource)\n",
    "\n",
    "        print(f\"Unused resources on {url}:\")\n",
    "        for unused in unused_resources:\n",
    "            print(unused)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    target_url = 'https://thestudyvarta.blogspot.com/'\n",
    "    get_unused_resources(target_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c419cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
